---
title: "linear regression, Stepwise Model selection"
author: "Arash Hatamirad, ahatamirad@gmail.com"
date: "9/1/2021"
output:
  html_document: default
  word_document: default
  pdf_document: default  
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_knit$set(root.dir = "C:/Users/Sanaz/Documents/All_MSDA_Projects and Sources/R Ptojects/Algorithm I/HW03/AlgorithmI-HW3")

# Install required packages

# install.packages("MASS")
# install.packages("fBasics")
# install.packages("moments")
# install.packages("dplyr")
# install.packages("car")
#install.packages("DescTools")
#install.packages("olsrr")

library(MASS)
library(fBasics)
library(moments)
library(dplyr)
library(car)
library(DescTools)
library(olsrr)


# 000000000


#Data: heartbpchol.csv for Exercise1, 
# bupa.csv for Exercise 2, 
# psych.csv for Exercise3, 
# cars_new.csv for Exercise 4
```



## Stepwise selection 


We will use heart.csv dataset. Below is brief summary of variables in heart.csv.  

- Weight: subject’s weight  
- Systolic: top number in a blood pressure reading, indicating the blood pressure level when the heart contracts  
- Diastolic: bottom number in a blood pressure reading, indicating the blood pressure level when the heart is at rest or between beats  
- Cholesterol: measured cholesterol  

The data set contains Weight, Diastolic Blood pressure, Systolic blood pressure and Cholesterol for alive subjects in the heart.csv.   


```{r}

# Read the CSV file
d1 <- read.csv("heart.csv") 

# Check data format
#str(d1)

```

consider stepwise model selection for the Cholesterol model. Before performing the model selection, which has a cook’s distance larger than 0.015.    
   

***


- Find the best model based on adjusted-R square criteria and specify which predictors are selected.  
 
 
#### Answer -:



##### Step 1) Run linear regressions with multicollinearity issue  
```{r}
e2.lr <- lm( Cholesterol ~ Diastolic+Systolic+Weight  , data=d1)
summary(e2.lr)

```
##### Result:   
- P-Value of F-Test is significant. Thus, the model is useful. 
        
In the other word, there exist linear regression for cholesterol as a function of diastolic, systolic, and weight.


##### Step 2) Perform Correlation to find Multicollinearity   
- Two methods:
        
          - 1) Pairwise Scatter Plot  
        
          - 2) Quantitative Method (VIF's)  

```{r}
pairs(d1,pch=19, col="darkblue")

```

##### Result:   
- It seems, maybe there exist a small correlation between Diastolic and Systolic, to be sure
we will perform a Quantitative test (VIF's)     

```{r}
vif(e2.lr)
```
##### Result:   
- There is no VIF>10, thus there exist no correlation between predictors.  


##### Step 3) Perform Diagnostic Plot    
```{r}
par(mfrow=c(2,2))
plot(e2.lr,which=1:4,col="darkblue")
```

##### Result:   
- It seems a normal distribution in Normal QQ plot, in Standardized residual, 95% data are between 0-1.5, thus data follow normal distribution.  
        
- In the Residuals plot, there is no pattern, thus there exist a Homoscedasticity.  
        
- In the cook distance, there exist some pints greater than 0.015  
        



##### Step 4) Influential points
```{r}
cook.d2 <- cooks.distance(e2.lr)
plot(cook.d2,col="darkblue",pch=19,cex=1)

```


- Delete observations larger than criteria (0.015)  

```{r}
e2.inf.id <- which(cooks.distance(e2.lr)>0.015)
e2.lr2 <- lm(Cholesterol ~ Diastolic+Systolic+Weight  , data=d1[-e2.inf.id,])
summary(e2.lr2)

```

##### Linear regression model:   

        ŷ = 156.32618 + 0.24922 * Diastolic + 0.30073 * Systolic + 0.03671 * Weight    

##### R Square (R2) and Adj. R Square: 

Calculate R2 and Adj.R2 
```{r}
summary(e2.lr2)$r.squared
summary(e2.lr2)$adj.r.squared
```
        R Square is very small, thus, "Goodness of fit" or "Predictive power" is very low.  
        
        Adj. R Square is very small too.  


##### Step 5) Plot scatter, with and without influential points   
```{r}
with(d1,plot(Cholesterol ~ Diastolic+Systolic+Weight, col="darkblue"))
abline(e2.lr,col="red")
abline(e2.lr2,col="green")
legend("bottomright",col=c("red","green"),legend = c("W/Inf. points","W/out Inf. points"),cex=0.8,title.adj = 0.15,lty=1)


```


##### Result:  
- Since dataset is very big (3134 observations) and we only remove 2 outliers, 
thus, the linear regression is closed together. The red line is under the green line.   


##### Step 6) Diagnostic plot for without influential points  

```{r}
par(mfrow=c(2,2))
plot(e2.lr2, which=c(1:4),col="darkblue") 
```


#### Conclusion:
Regression lines with/without influential points are almost the same.

***  

### Perform stepwise model selection


- Perform stepwise model selection with .05 criteria and address any issues in diagnostics plots.

#### Answer -: 

We have removed influential points detected in Exercise 2, which has a cook’s distance larger than 0.015.   
(We will use "data=d1[-e2.inf.id,]" dataset, which have deleted the influential points)  


```{r}
e3.model.stepwise <- ols_step_both_p(e2.lr2,pent = 0.05, prem = 0.05, details = F)
e3.model.stepwise

```
```{r}
plot(e3.model.stepwise)
```

```{r}
e3.lr.stepwise <- lm(Cholesterol ~ Diastolic+Systolic, data=d1[-e2.inf.id,])
summary(e3.lr.stepwise)
```


#### Conclusion:   
- The model is significant and each individual variable is also significant.   


